{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f63eb902",
   "metadata": {},
   "source": [
    "# Lab 2: Configure Azure AI Search RAG Knowledge Base\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook configures a RAG (Retrieval-Augmented Generation) knowledge base using Azure AI Search.\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                  RAG Pipeline                            ‚îÇ\n",
    "‚îÇ                                                          ‚îÇ\n",
    "‚îÇ  Documents (JSON) ‚Üí Embeddings (OpenAI)                 ‚îÇ\n",
    "‚îÇ                         ‚Üì                                ‚îÇ\n",
    "‚îÇ              Azure AI Search Index                       ‚îÇ\n",
    "‚îÇ           (Vector Store + Keyword Search)                ‚îÇ\n",
    "‚îÇ                         ‚Üì                                ‚îÇ\n",
    "‚îÇ            Hybrid Search (Vector + BM25)                 ‚îÇ\n",
    "‚îÇ                         ‚Üì                                ‚îÇ\n",
    "‚îÇ              Research Agent Query                        ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "Upon completing this lab, you will be able to:\n",
    "\n",
    "1. ‚úÖ Design and create Azure AI Search index schema\n",
    "2. ‚úÖ Generate text embeddings with Azure OpenAI\n",
    "3. ‚úÖ Upload documents for vector and keyword search\n",
    "4. ‚úÖ Execute and test hybrid search (vector + BM25)\n",
    "5. ‚úÖ Evaluate and optimize RAG pipeline performance\n",
    "\n",
    "### Data to Use\n",
    "\n",
    "- **data/knowledge-base.json**: 50 diverse Korean travel destination information entries\n",
    "- **Categories**: Nature/Healing, Culture/History, City/Beach, Activity/Sports, Food/Market\n",
    "- **Embedding Model**: text-embedding-3-large (3072 dimensions)\n",
    "- **Search Testing**: Dataset that clearly demonstrates the strengths of vector/keyword/hybrid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c404e5a7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚öôÔ∏è Before You Start\n",
    "\n",
    "**Select a Python kernel:**\n",
    "\n",
    "1. Click **\"Select Kernel\"** at the top right of the notebook\n",
    "2. Select **\"Python Environments...\"**\n",
    "3. Choose **`.venv (Python 3.x.x)`** (virtual environment created in the project root)\n",
    "\n",
    "> üí° **GitHub Codespaces**: In Codespaces, the `.venv` environment is automatically created.  \n",
    "> If you don't see `.venv`, create it with `python -m venv .venv` in the terminal.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dbfc09",
   "metadata": {},
   "source": [
    "## 1. Prerequisites Check\n",
    "\n",
    "Verify that the following tools are installed:\n",
    "\n",
    "- Python 3.9 or higher\n",
    "- Azure CLI\n",
    "- Azure Developer CLI (azd)\n",
    "- Docker (required for Container Apps deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3482f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, subprocess, os\n",
    "import platform\n",
    "\n",
    "# Set PATH based on operating system (supports macOS, Linux, and Codespaces)\n",
    "system = platform.system()\n",
    "if system == 'Darwin':  # macOS\n",
    "    # Add Homebrew paths (Intel & Apple Silicon)\n",
    "    extra_paths = '/opt/homebrew/bin:/usr/local/bin'\n",
    "elif system == 'Linux':  # Linux / Codespaces\n",
    "    # Common Linux binary paths\n",
    "    extra_paths = '/usr/local/bin:/usr/bin:/home/codespace/.local/bin'\n",
    "else:  # Windows\n",
    "    extra_paths = ''\n",
    "\n",
    "if extra_paths:\n",
    "    os.environ['PATH'] = extra_paths + ':' + os.environ.get('PATH', '')\n",
    "\n",
    "def check(cmd, name):\n",
    "    try:\n",
    "        result = subprocess.run(cmd, shell=True, capture_output=True, timeout=3, env=os.environ)\n",
    "        print(f\"{'‚úì' if result.returncode == 0 else '‚úó'} {name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó {name}\")\n",
    "\n",
    "print(\"=== Prerequisites Check ===\")\n",
    "print(f\"‚úì Python {sys.version.split()[0]} ({system})\")\n",
    "check(\"az --version\", \"Azure CLI\")\n",
    "check(\"azd version\", \"Azure Developer CLI\")\n",
    "check(\"docker --version\", \"Docker\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19bf7a4",
   "metadata": {},
   "source": [
    "## 2. Install Required Packages\n",
    "\n",
    "Install essential Azure AI-related packages. If you're running in GitHub Codespaces, most packages may already be installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7c953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = [\n",
    "    \"azure-search-documents\",\n",
    "    \"azure-identity\",\n",
    "    \"openai\",\n",
    "    \"python-dotenv\"\n",
    "]\n",
    "\n",
    "print(\"=== Installing Required Packages ===\\n\")\n",
    "\n",
    "for package in packages:\n",
    "    print(f\"Installing {package}...\")\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package],\n",
    "        capture_output=True,\n",
    "        text=True\n",
    "    )\n",
    "    if result.returncode == 0:\n",
    "        print(f\"‚úÖ {package} installed\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  {package} may already be installed or failed to install\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"‚úÖ Package installation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52071fff",
   "metadata": {},
   "source": [
    "## 3. Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3337d715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration file saved from Notebook 1\n",
    "import json\n",
    "import os\n",
    "\n",
    "config_path = \"./config.json\"\n",
    "\n",
    "if not os.path.exists(config_path):\n",
    "    raise FileNotFoundError(\n",
    "        f\"‚ùå Configuration file not found: {config_path}\\n\"\n",
    "        \"Please run Notebook 1 (01_deploy_azure_resources.ipynb) first.\"\n",
    "    )\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Verify required settings (no keys needed when using Managed Identity)\n",
    "required_keys = [\"search_endpoint\", \"project_connection_string\"]\n",
    "missing_keys = [key for key in required_keys if not config.get(key)]\n",
    "\n",
    "if missing_keys:\n",
    "    raise ValueError(f\"‚ùå Required settings are missing: {', '.join(missing_keys)}\")\n",
    "\n",
    "print(\"‚úÖ Configuration file loaded successfully\")\n",
    "print(f\"üìç Search Endpoint: {config['search_endpoint']}\")\n",
    "print(f\"üìç AI Project Connection: {'‚úì Set' if config['project_connection_string'] else '‚úó Missing'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297495cc",
   "metadata": {},
   "source": [
    "## 4. Azure Authentication\n",
    "\n",
    "Although we already logged into Azure in Lab 1, the session may have expired, so we'll verify authentication status and re-authenticate if necessary.\n",
    "\n",
    "### Tenant ID Setup Guide\n",
    "\n",
    "**In most cases**: You don't need to specify a tenant ID. Leave the `tenant_id` variable as `\"<YOUR_TENANT_ID>\"` or `None` and run.\n",
    "\n",
    "**When Tenant ID is required**:\n",
    "- ‚úÖ When you have access to multiple Azure tenants (organizations/companies)\n",
    "- ‚úÖ When you need to work only with resources from a specific organization\n",
    "- ‚úÖ When you encounter \"multiple tenants\" related errors during login\n",
    "\n",
    "**How to find your Tenant ID**:\n",
    "- Azure Portal ‚Üí Azure Active Directory ‚Üí Overview ‚Üí Copy Tenant ID\n",
    "- Or contact your organization administrator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fe134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, json\n",
    "\n",
    "print(\"=== Azure Authentication ===\")\n",
    "print(\"‚ÑπÔ∏è  Checking authentication status and logging in if necessary.\\n\")\n",
    "\n",
    "# Enter your tenant ID here (optional)\n",
    "# Example: tenant_id = \"16b3c013-d300-468d-ac64-7eda0820b6d3\"\n",
    "tenant_id = \"<YOUR_TENANT_ID>\"  # Or set to None to use the default tenant\n",
    "\n",
    "# Check Azure CLI authentication status\n",
    "az_account = subprocess.run(\"az account show\", shell=True, capture_output=True, text=True)\n",
    "\n",
    "if az_account.returncode == 0:\n",
    "    account_info = json.loads(az_account.stdout)\n",
    "    print(f\"‚úÖ Azure CLI authentication successful (using existing session)\")\n",
    "    print(f\"   Subscription: {account_info.get('name', 'N/A')}\")\n",
    "    print(f\"   Tenant: {account_info.get('tenantId', 'N/A')}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Azure CLI authentication required. Opening browser...\")\n",
    "    # Login with tenant ID if set\n",
    "    if tenant_id and tenant_id != \"<YOUR_TENANT_ID>\":\n",
    "        az_login = subprocess.run(f\"az login --tenant {tenant_id}\", shell=True)\n",
    "    else:\n",
    "        az_login = subprocess.run(\"az login\", shell=True)\n",
    "    \n",
    "    if az_login.returncode == 0:\n",
    "        print(\"‚úÖ Azure CLI login successful\")\n",
    "    else:\n",
    "        raise Exception(\"‚ùå Azure CLI login failed\")\n",
    "\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9e0739",
   "metadata": {},
   "source": [
    "## 5. Load Knowledge Base Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280a30d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load knowledge base JSON file\n",
    "knowledge_base_path = \"./data/knowledge-base.json\"\n",
    "\n",
    "if not os.path.exists(knowledge_base_path):\n",
    "    raise FileNotFoundError(f\"‚ùå Knowledge base file not found: {knowledge_base_path}\")\n",
    "\n",
    "with open(knowledge_base_path, 'r', encoding='utf-8') as f:\n",
    "    knowledge_base = json.load(f)\n",
    "\n",
    "# JSON can be a direct array or wrapped in documents\n",
    "if isinstance(knowledge_base, list):\n",
    "    documents = knowledge_base\n",
    "else:\n",
    "    documents = knowledge_base.get(\"documents\", [])\n",
    "\n",
    "print(f\"‚úÖ Travel destination knowledge base loaded successfully\")\n",
    "print(f\"üìö Total destinations: {len(documents)}\")\n",
    "print(f\"\\nüìÇ Destinations by category:\")\n",
    "\n",
    "# Classify by category\n",
    "from collections import Counter\n",
    "categories = Counter(doc.get(\"section\", doc.get(\"category\", \"Other\")) for doc in documents)\n",
    "for category, count in sorted(categories.items()):\n",
    "    print(f\"  ‚Ä¢ {category}: {count} destinations\")\n",
    "\n",
    "# Display first document sample\n",
    "if documents:\n",
    "    print(f\"\\nüìÑ Sample destination:\")\n",
    "    sample = documents[0]\n",
    "    print(f\"  ID: {sample['id']}\")\n",
    "    print(f\"  Title: {sample['title']}\")\n",
    "    print(f\"  Category: {sample['category']}\")\n",
    "    print(f\"  Section: {sample.get('section', 'N/A')}\")\n",
    "    print(f\"  Content length: {len(sample['content'])} characters\")\n",
    "    if 'metadata' in sample and 'tags' in sample['metadata']:\n",
    "        print(f\"  Tags: {', '.join(sample['metadata']['tags'][:5])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7172f319",
   "metadata": {},
   "source": [
    "## 6. Create Azure AI Search Index\n",
    "\n",
    "### üìã Index Schema Design\n",
    "\n",
    "The core of a RAG system is an **efficient index schema**. Index structure created in this Lab:\n",
    "\n",
    "---\n",
    "\n",
    "### üîë Key Field Descriptions\n",
    "\n",
    "| Field | Type | Role | Attributes |\n",
    "|------|------|------|------|\n",
    "| **id** | String | Unique identifier | `key=True` (required) |\n",
    "| **title** | String | Document title | `searchable=True` (keyword search) |\n",
    "| **content** | String | Body content | `searchable=True`, Korean analyzer |\n",
    "| **contentVector** | Float[] | Embedding vector | `dimensions=3072` (vector search) |\n",
    "| **category** | String | Category | `filterable=True` (filtering) |\n",
    "| **tags** | String[] | Tag list | `filterable=True` (multi-filter) |\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Vector Search Configuration (HNSW Algorithm)\n",
    "\n",
    "**Core settings for contentVector field:**\n",
    "\n",
    "```python\n",
    "VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(\n",
    "            name=\"hnsw-config\",\n",
    "            parameters=HnswParameters(\n",
    "                m=4,                    # Graph connectivity\n",
    "                ef_construction=400,    # Indexing quality\n",
    "                metric=\"cosine\"         # Similarity metric\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"vector-profile\",\n",
    "            algorithm_configuration_name=\"hnsw-config\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "```\n",
    "\n",
    "**Parameter Meanings:**\n",
    "\n",
    "| Parameter | Value | Meaning | Impact |\n",
    "|----------|-----|------|------|\n",
    "| **m** | 4 | Connections per node | Higher = more accurate but slower |\n",
    "| **ef_construction** | 400 | Build-time search depth | Higher = better index quality |\n",
    "| **metric** | cosine | Similarity calculation | Optimized for embeddings |\n",
    "\n",
    "**HNSW vs Other Algorithms:**\n",
    "\n",
    "| Algorithm | Search Speed | Accuracy | Memory | Index Build Speed | Recommended Use |\n",
    "|---------|----------|--------|--------|-----------------|-----------|\n",
    "| **HNSW** | ‚ö°‚ö°‚ö° Fast | ‚≠ê‚≠ê‚≠ê High (approximate) | Medium | Fast | **Production RAG** ‚≠ê |\n",
    "| **Exhaustive KNN** | ‚ö° Slow | ‚≠ê‚≠ê‚≠ê‚≠ê Perfect (100%) | Low | Instant | Small scale (<1K docs), highest accuracy needed |\n",
    "| Flat (Brute Force) | Slow | Perfect | Low | Instant | Small scale (<1K docs) |\n",
    "| IVF | Fast | Medium | High | Slow | Large scale (>1M docs) |\n",
    "\n",
    "\n",
    "**Lab Choice:** HNSW - optimal for 50 documents and scalable\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Index Configuration Summary\n",
    "\n",
    "Final configuration of the created index:\n",
    "\n",
    "```yaml\n",
    "Index name: agentic-ai-knowledge-base\n",
    "Fields: 6\n",
    "  - Keyword search: title, content (ko.microsoft)\n",
    "  - Vector search: contentVector (3072 dimensions, HNSW)\n",
    "  - Filtering: category, tags\n",
    "Vector algorithm: HNSW (m=4, ef_construction=400)\n",
    "Language support: Korean (ko.microsoft analyzer)\n",
    "```\n",
    "\n",
    "**Next Step:** Embed and upload documents according to this schema! üì§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcdaf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    SearchIndex,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    VectorSearch,\n",
    "    VectorSearchProfile,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    SimpleField,\n",
    "    SearchableField\n",
    ")\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import subprocess\n",
    "\n",
    "# Get Azure AI Search Admin Key\n",
    "print(\"üîë Retrieving AI Search Admin Key...\")\n",
    "search_service_name = config.get(\"search_service_name\", \"\")\n",
    "resource_group = config.get(\"resource_group\", \"\")\n",
    "\n",
    "key_result = subprocess.run(\n",
    "    f\"az search admin-key show --resource-group {resource_group} --service-name {search_service_name} --query primaryKey -o tsv\",\n",
    "    shell=True,\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "if key_result.returncode != 0:\n",
    "    raise Exception(f\"‚ùå Failed to retrieve Admin Key: {key_result.stderr}\")\n",
    "\n",
    "search_admin_key = key_result.stdout.strip()\n",
    "print(\"‚úÖ Admin Key acquired successfully\")\n",
    "\n",
    "# Create Search Index Client (Admin Key authentication)\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=config[\"search_endpoint\"],\n",
    "    credential=AzureKeyCredential(search_admin_key)\n",
    ")\n",
    "print(\"‚úÖ Search Index Client created (Admin Key authentication)\")\n",
    "\n",
    "# Set index name\n",
    "index_name = \"ai-agent-knowledge-base\"\n",
    "\n",
    "# Define index schema\n",
    "fields = [\n",
    "    SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True),\n",
    "    SearchableField(name=\"title\", type=SearchFieldDataType.String, \n",
    "                   filterable=True, sortable=True),\n",
    "    SearchableField(name=\"content\", type=SearchFieldDataType.String, \n",
    "                   analyzer_name=\"ko.microsoft\"),  # Korean analyzer\n",
    "    SimpleField(name=\"category\", type=SearchFieldDataType.String, \n",
    "               filterable=True, sortable=True, facetable=True),\n",
    "    SimpleField(name=\"section\", type=SearchFieldDataType.String, \n",
    "               filterable=True, sortable=False),\n",
    "    SearchField(\n",
    "        name=\"contentVector\",\n",
    "        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "        searchable=True,\n",
    "        vector_search_dimensions=3072,  # text-embedding-3-large\n",
    "        vector_search_profile_name=\"vector-profile\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Vector search configuration\n",
    "vector_search = VectorSearch(\n",
    "    algorithms=[\n",
    "        HnswAlgorithmConfiguration(name=\"hnsw-algorithm\")\n",
    "    ],\n",
    "    profiles=[\n",
    "        VectorSearchProfile(\n",
    "            name=\"vector-profile\",\n",
    "            algorithm_configuration_name=\"hnsw-algorithm\"\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create index\n",
    "index = SearchIndex(\n",
    "    name=index_name,\n",
    "    fields=fields,\n",
    "    vector_search=vector_search\n",
    ")\n",
    "\n",
    "# Delete existing index and recreate\n",
    "try:\n",
    "    index_client.delete_index(index_name)\n",
    "    print(f\"‚ö†Ô∏è Existing index '{index_name}' deleted\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "result = index_client.create_index(index)\n",
    "print(f\"‚úÖ Index created successfully: {result.name}\")\n",
    "print(f\"üìä Number of fields: {len(result.fields)}\")\n",
    "print(\"üîç Vector search: Enabled (3072 dimensions)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf8b1e8",
   "metadata": {},
   "source": [
    "## 7. Generate Embeddings with Azure OpenAI\n",
    "\n",
    "### üß† What is Text Embedding?\n",
    "\n",
    "Converting text into numeric vectors so computers can understand and compare **meaning**.\n",
    "\n",
    "```\n",
    "\"Agent security\"  ‚Üí  [0.123, -0.456, ..., 0.234]  (3072 numbers)\n",
    "\"agent security\" ‚Üí  [0.119, -0.451, ..., 0.228]  (very similar vector!)\n",
    "```\n",
    "\n",
    "**Key Point:** Semantically similar text = similar vectors ‚Üí basis for RAG search\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ text-embedding-3-large Model\n",
    "\n",
    "**OpenAI's latest embedding model (released in 2024)**\n",
    "\n",
    "| Model | Dimensions | Performance | Suitable For |\n",
    "|------|------|------|------------|\n",
    "| **text-embedding-3-large** | 3072 | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | **Production RAG (recommended)** |\n",
    "| text-embedding-3-small | 1536 | ‚≠ê‚≠ê‚≠ê‚≠ê | Quick prototypes, cost savings |\n",
    "| text-embedding-ada-002 | 1536 | ‚≠ê‚≠ê‚≠ê | Old model (legacy) |\n",
    "\n",
    "**Meaning of 3072 dimensions:**\n",
    "- More dimensions = finer semantic distinctions\n",
    "- MTEB benchmark: **64.6%** (ada-002: 61.0%)\n",
    "- Can handle long text (~8,191 tokens)\n",
    "\n",
    "---\n",
    "\n",
    "### üìê Embedding Generation Process\n",
    "\n",
    "```\n",
    "Text Input ‚Üí Tokenization ‚Üí Transformer Processing ‚Üí Vector Generation ‚Üí Normalization\n",
    "```\n",
    "\n",
    "**Implementation in this Lab:**\n",
    "```python\n",
    "def generate_embedding(text: str) -> list[float]:\n",
    "    response = openai_client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-large\",\n",
    "        dimensions=3072  # Explicitly specify 3072 dimensions\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Generate embedding by combining title + content\n",
    "text_to_embed = f\"{doc['title']}\\n\\n{doc['content']}\"\n",
    "doc[\"contentVector\"] = generate_embedding(text_to_embed)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067b4c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "import time\n",
    "\n",
    "# Create Azure OpenAI client (using Managed Identity)\n",
    "token_provider = get_bearer_token_provider(\n",
    "    DefaultAzureCredential(),\n",
    "    \"https://cognitiveservices.azure.com/.default\"\n",
    ")\n",
    "\n",
    "# Extract OpenAI endpoint from project connection string\n",
    "# Format 1: https://aoai-xxx.services.ai.azure.com/api/projects/proj-xxx;...\n",
    "# Format 2: workspace=...;subscription_id=...;resource_group=...;aiservices_name=...\n",
    "import re\n",
    "\n",
    "project_conn_str = config['project_connection_string']\n",
    "\n",
    "# Extract AI Services name from URL (Format 1)\n",
    "url_match = re.match(r'https://([^.]+)\\.', project_conn_str)\n",
    "if url_match:\n",
    "    aiservices_name = url_match.group(1)\n",
    "    openai_endpoint = f\"https://{aiservices_name}.openai.azure.com/\"\n",
    "else:\n",
    "    # Extract from key-value format (Format 2)\n",
    "    conn_parts = {}\n",
    "    for part in project_conn_str.split(';'):\n",
    "        if '=' in part:\n",
    "            key, value = part.split('=', 1)\n",
    "            conn_parts[key] = value\n",
    "    \n",
    "    aiservices_name = conn_parts.get('aiservices_name', '')\n",
    "    if not aiservices_name:\n",
    "        raise ValueError(\"‚ùå AI Services name not found. Please check project_connection_string in config.json.\")\n",
    "    \n",
    "    openai_endpoint = f\"https://{aiservices_name}.openai.azure.com/\"\n",
    "\n",
    "print(f\"üîó Azure OpenAI Endpoint: {openai_endpoint}\")\n",
    "\n",
    "openai_client = AzureOpenAI(\n",
    "    azure_ad_token_provider=token_provider,\n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_endpoint=openai_endpoint\n",
    ")\n",
    "\n",
    "# Set embedding model\n",
    "embedding_model = \"text-embedding-3-large\"\n",
    "\n",
    "def generate_embedding(text: str) -> list[float]:\n",
    "    \"\"\"Convert text to vector\"\"\"\n",
    "    response = openai_client.embeddings.create(\n",
    "        input=text,\n",
    "        model=embedding_model,\n",
    "        dimensions=3072  # Explicitly set to 3072 dimensions\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "# Generate embeddings for all documents\n",
    "print(\"üîÑ Generating embeddings...\")\n",
    "print(f\"üìÑ Documents to process: {len(documents)}\")\n",
    "\n",
    "for i, doc in enumerate(documents, 1):\n",
    "    # Generate embedding by combining title and content\n",
    "    text_to_embed = f\"{doc['title']}\\n\\n{doc['content']}\"\n",
    "    doc[\"contentVector\"] = generate_embedding(text_to_embed)\n",
    "    \n",
    "    print(f\"  [{i}/{len(documents)}] {doc['title'][:50]}... ‚úì\")\n",
    "    \n",
    "    # Prevent rate limit (consider TPM limit)\n",
    "    if i < len(documents):\n",
    "        time.sleep(0.5)\n",
    "\n",
    "print(f\"\\n‚úÖ Embedding generation completed\")\n",
    "print(f\"üìä Vector dimensions: {len(documents[0]['contentVector'])} dimensions (3072 dimensions)\")\n",
    "print(f\"üíæ Memory usage: ~{len(documents) * 3072 * 4 / 1024 / 1024:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f641525",
   "metadata": {},
   "source": [
    "## 8. Upload Documents to Azure AI Search\n",
    "\n",
    "### üì§ Batch Upload Strategy\n",
    "\n",
    "Azure AI Search recommends **batch upload**:\n",
    "\n",
    "| Batch Size | Processing Speed | Recommended Scenario |\n",
    "|-----------|-----------|-----------|\n",
    "| 1-10 | Slow | Real-time single document |\n",
    "| **10-100** | **Fast ‚≠ê** | **General indexing (recommended)** |\n",
    "| 100-1000 | Very fast | Bulk initial load |\n",
    "\n",
    "**Lab Usage: 50 documents ‚Üí single batch (optimal)**\n",
    "\n",
    "---\n",
    "\n",
    "### üîß upload_documents() Method\n",
    "\n",
    "```python\n",
    "search_client.upload_documents(documents=documents_with_embeddings)\n",
    "```\n",
    "\n",
    "**Internal Operation:**\n",
    "1. **Validation**: Check required fields (`id`, `contentVector`, etc.)\n",
    "2. **Serialization**: Convert to JSON array\n",
    "3. **HTTP POST**: `/docs/index` endpoint\n",
    "4. **Response Processing**: Return success/failure results per document\n",
    "\n",
    "**Response Example:**\n",
    "```json\n",
    "{\n",
    "  \"value\": [\n",
    "    {\"key\": \"doc1\", \"status\": true, \"statusCode\": 201},\n",
    "    {\"key\": \"doc2\", \"status\": true, \"statusCode\": 201}\n",
    "  ]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e6b50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents import SearchClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "# Create Search Client (for document upload)\n",
    "search_client = SearchClient(\n",
    "    endpoint=config[\"search_endpoint\"],\n",
    "    index_name=index_name,\n",
    "    credential=AzureKeyCredential(search_admin_key)\n",
    ")\n",
    "print(\"‚úÖ Search Client created (for document upload)\")\n",
    "\n",
    "# Clean documents (include only fields matching index schema)\n",
    "allowed_fields = {\"id\", \"title\", \"content\", \"category\", \"section\", \"contentVector\"}\n",
    "cleaned_documents = []\n",
    "\n",
    "for doc in documents:\n",
    "    cleaned_doc = {key: value for key, value in doc.items() if key in allowed_fields}\n",
    "    cleaned_documents.append(cleaned_doc)\n",
    "\n",
    "print(f\"\\nüì¶ Upload preparation:\")\n",
    "print(f\"   - Number of documents: {len(cleaned_documents)}\")\n",
    "print(f\"   - Fields: {', '.join(allowed_fields)}\")\n",
    "print(f\"   - Vector dimensions: {len(cleaned_documents[0]['contentVector'])}\")\n",
    "\n",
    "# Upload documents (batch)\n",
    "print(f\"\\nüîÑ Uploading documents...\")\n",
    "\n",
    "try:\n",
    "    result = search_client.upload_documents(documents=cleaned_documents)\n",
    "    \n",
    "    # Analyze upload results\n",
    "    succeeded = sum(1 for r in result if r.succeeded)\n",
    "    failed = len(result) - succeeded\n",
    "    \n",
    "    print(f\"\\n‚úÖ Upload completed!\")\n",
    "    print(f\"   - Succeeded: {succeeded}\")\n",
    "    print(f\"   - Failed: {failed}\")\n",
    "    \n",
    "    if failed > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è Failed documents:\")\n",
    "        for r in result:\n",
    "            if not r.succeeded:\n",
    "                print(f\"   - {r.key}: {r.error_message}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Upload failed: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "print(f\"\\nüìä Index status:\")\n",
    "print(f\"   - Index name: {index_name}\")\n",
    "print(f\"   - Total documents: {len(cleaned_documents)}\")\n",
    "print(f\"   - Search ready! üéâ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12749581",
   "metadata": {},
   "source": [
    "## 9. Hybrid Search Example\n",
    "\n",
    "### üîç What is Hybrid Search?\n",
    "\n",
    "**Hybrid search** combines **vector search** and **keyword search** to leverage the advantages of both:\n",
    "\n",
    "| Search Method | Algorithm | Strengths | Weaknesses |\n",
    "|-----------|----------|------|------|\n",
    "| **Keyword Search** | BM25 | Exact word/phrase matching | Cannot understand synonyms/meaning |\n",
    "| **Vector Search** | Cosine similarity | Understands semantic similarity | Weaker exact term matching |\n",
    "| **Hybrid** | RRF (rank fusion) | **Combines both advantages** ‚≠ê | Slightly increased computational cost |\n",
    "\n",
    "---\n",
    "\n",
    "### ‚öôÔ∏è RRF (Reciprocal Rank Fusion) Algorithm\n",
    "\n",
    "Hybrid search uses **RRF** to fuse two search results:\n",
    "\n",
    "```\n",
    "RRF Score = 1/(k + vector_rank) + 1/(k + keyword_rank)\n",
    "           (k = 60, Azure AI Search default)\n",
    "```\n",
    "\n",
    "**Example:**\n",
    "- Document A: Vector rank 1, Keyword rank 3 ‚Üí RRF = 1/61 + 1/63 = 0.0323\n",
    "- Document B: Vector rank 2, Keyword rank 1 ‚Üí RRF = 1/62 + 1/61 = 0.0325 ‚Üê **Higher (priority)**\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Practice Query Analysis\n",
    "\n",
    "**Query:** \"Healing travel destination with ocean view\"\n",
    "\n",
    "This query is optimized for hybrid search:\n",
    "- **Keyword strength**: \"ocean\" (exact location feature)\n",
    "- **Vector strength**: \"healing travel destination\" (conceptual question)\n",
    "- **Hybrid effect**: Considers both exact location features + atmosphere/feel\n",
    "\n",
    "Execute search in the next cell, then compare 3 search methods in **Section 10**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78615bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.search.documents.models import VectorizedQuery\n",
    "\n",
    "# ‚úÖ Practice query: location feature + conceptual question (optimal for hybrid search)\n",
    "# Both keyword (\"ocean\") and meaning (\"healing\") are important\n",
    "test_query = \"Healing travel destinations with ocean views\"\n",
    "\n",
    "print(f\"üîç Search query: '{test_query}'\")\n",
    "print(f\"üìå This query includes both exact location features (ocean) and conceptual meaning (healing).\")\n",
    "print(f\"   ‚Üí Hybrid search is expected to provide the most accurate results.\\n\")\n",
    "\n",
    "# 1Ô∏è‚É£ Convert query to vector (embedding)\n",
    "print(\"üîÑ Generating query embedding...\")\n",
    "query_vector = generate_embedding(test_query)\n",
    "print(f\"‚úÖ Embedding generation completed (dimensions: {len(query_vector)})\\n\")\n",
    "\n",
    "# 2Ô∏è‚É£ Create vector query object\n",
    "vector_query = VectorizedQuery(\n",
    "    vector=query_vector,         # Query embedding vector\n",
    "    k_nearest_neighbors=5,       # Search top 5 similar documents\n",
    "    fields=\"contentVector\"       # Target vector field for search\n",
    ")\n",
    "\n",
    "# 3Ô∏è‚É£ Execute hybrid search (vector + keyword)\n",
    "print(\"üîç Executing hybrid search...\")\n",
    "results = search_client.search(\n",
    "    search_text=test_query,      # Keyword search (BM25 algorithm)\n",
    "    vector_queries=[vector_query],  # Vector search (cosine similarity)\n",
    "    select=[\"title\", \"content\", \"category\"],\n",
    "    top=5  # Return only top 5 results\n",
    ")\n",
    "\n",
    "# 4Ô∏è‚É£ Display search results\n",
    "print(\"=\" * 100)\n",
    "print(\"üìä Hybrid Search Results (Vector + Keyword)\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "result_count = 0\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"\\nüîπ Result {i}\")\n",
    "    print(f\"   üìÇ Category: {result['category']}\")\n",
    "    print(f\"   üìÑ Title: {result['title']}\")\n",
    "    print(f\"   üìù Content preview: {result['content'][:150]}...\")\n",
    "    result_count = i\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(f\"‚úÖ Search completed! Total {result_count} destinations found\")\n",
    "print(\"üí° Next section will compare keyword/vector/hybrid search.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f2f68e",
   "metadata": {},
   "source": [
    "## 10. Search Performance Comparison\n",
    "\n",
    "### üî¨ Comparison Experiment of 3 Search Methods\n",
    "\n",
    "This section clearly demonstrates the differences between each search method through **travel destination search scenarios**.\n",
    "\n",
    "---\n",
    "\n",
    "### üìä Characteristics by Search Method\n",
    "\n",
    "| Search Method | Algorithm | Key Advantages | Key Disadvantages | Recommended Use Cases |\n",
    "|-----------|----------|----------|----------|-----------------|\n",
    "| **Keyword Search** | BM25 | Exact word matching, fast speed | Cannot understand synonyms/meaning | **Specific place names/proper nouns** ‚≠ê, festival names, restaurant names |\n",
    "| **Vector Search** | Cosine similarity | Semantic-based, synonym handling, atmosphere understanding | Weaker exact place name matching | Natural language questions, feel/atmosphere-based search |\n",
    "| **Hybrid (RRF)** | Vector + BM25 fusion | **Combines advantages of both** ‚≠ê | Slightly increased computational cost | **Production RAG (recommended)** |\n",
    "\n",
    "---\n",
    "\n",
    "### üß™ Experimental Scenario: Specific Theme Travel Destination Search\n",
    "\n",
    "**Query:** \"Beach where you can surf\"\n",
    "\n",
    "This query clearly shows the differences between each search method:\n",
    "\n",
    "1. **Keyword Search (Expected: exact matching)**\n",
    "   - Search only destinations that exactly contain the string \"surf\"\n",
    "   - Surf spots like Yangyang, Busan will be ranked high\n",
    "\n",
    "2. **Vector Search (Expected: includes related activities)**\n",
    "   - Search destinations semantically similar to \"water leisure\", \"marine sports\"\n",
    "   - May include marine activity-related places even without explicit mention of surfing\n",
    "\n",
    "3. **Hybrid Search (Expected: balanced results)**\n",
    "   - Exact surf spots + related marine activity places\n",
    "   - Provides most comprehensive results\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Search Method Selection Guide\n",
    "\n",
    "**Hybrid Search (recommended for 90% of cases):**\n",
    "- ‚úÖ Answering general user questions\n",
    "- ‚úÖ Complex queries (place name + theme/atmosphere)\n",
    "- ‚úÖ Production environments where accuracy is important\n",
    "\n",
    "**Keyword-only Search:**\n",
    "- ‚úÖ Specific place name search (e.g., \"Jeju Island\", \"Gyeongju\")\n",
    "- ‚úÖ Festival names/proper nouns (e.g., \"Mud Festival\", \"Lantern Festival\")\n",
    "- ‚úÖ Specialty products/food names (e.g., \"snow crab\", \"bibimbap\")\n",
    "\n",
    "**Vector-only Search:**\n",
    "- ‚úÖ When semantic similarity is important (feeling, atmosphere)\n",
    "- ‚úÖ Natural language questions (e.g., \"good place for family\")\n",
    "- ‚úÖ Conceptual questions (e.g., \"healing travel\" ‚âà \"relaxation trip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48817640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "\n",
    "# üß™ Experiment: Query that clearly shows strengths of each search method\n",
    "# \"Surfing\": exact activity name (keyword search strength)\n",
    "# \"Beach\": location type (vector search can find related places)\n",
    "# ‚Üí Hybrid considers both\n",
    "\n",
    "test_query = \"Beaches where you can surf\"\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"üß™ Search Experiment: Specific Activity Travel Destination Search\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"üìå Query: '{test_query}'\")\n",
    "print(f\"üí° Expected: Keyword search will be most accurate (exact activity name matching)\")\n",
    "print(f\"   - Keyword search: Finds exact 'surfing' string ‚≠ê\")\n",
    "print(f\"   - Vector search: Also includes semantically similar marine activity places\")\n",
    "print(f\"   - Hybrid: Combines both for balanced results\\n\")\n",
    "\n",
    "# Generate query embedding (once)\n",
    "print(\"üîÑ Generating search query embedding...\")\n",
    "query_vector = generate_embedding(test_query)\n",
    "vector_query = VectorizedQuery(vector=query_vector, k_nearest_neighbors=3, fields=\"contentVector\")\n",
    "print(\"‚úÖ Embedding generation completed\\n\")\n",
    "sys.stdout.flush()  # Force flush output buffer\n",
    "\n",
    "# === Method 1: Keyword-only Search (recommended: specific activity/place name search) ===\n",
    "print(\"üîç Method 1: Keyword-only Search (BM25)\")\n",
    "print(\"   ‚Üí Search destinations that exactly match 'surfing' string\")\n",
    "print(\"-\" * 100)\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Execute search and collect results (synchronous)\n",
    "keyword_search_results = search_client.search(\n",
    "    search_text=test_query,\n",
    "    vector_queries=None,  # Disable vector search\n",
    "    select=[\"title\", \"category\", \"section\"],\n",
    "    top=3\n",
    ")\n",
    "keyword_results = []\n",
    "for result in keyword_search_results:\n",
    "    keyword_results.append(result)\n",
    "\n",
    "# Display results\n",
    "for i, r in enumerate(keyword_results, 1):\n",
    "    section = r.get('section', 'Other')\n",
    "    print(f\"   {i}. [{section}] {r['title']}\")\n",
    "sys.stdout.flush()\n",
    "time.sleep(0.1)  # Wait for output completion\n",
    "\n",
    "# === Method 2: Vector-only Search ===\n",
    "print(\"\\nüîç Method 2: Vector-only Search (Cosine Similarity)\")\n",
    "print(\"   ‚Üí Search semantically similar destinations (marine activity focused)\")\n",
    "print(\"-\" * 100)\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Execute search and collect results (synchronous)\n",
    "vector_search_results = search_client.search(\n",
    "    search_text=None,  # Disable keyword search\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"title\", \"category\", \"section\"],\n",
    "    top=3\n",
    ")\n",
    "vector_results = []\n",
    "for result in vector_search_results:\n",
    "    vector_results.append(result)\n",
    "\n",
    "# Display results\n",
    "for i, r in enumerate(vector_results, 1):\n",
    "    section = r.get('section', 'Other')\n",
    "    print(f\"   {i}. [{section}] {r['title']}\")\n",
    "sys.stdout.flush()\n",
    "time.sleep(0.1)  # Wait for output completion\n",
    "\n",
    "# === Method 3: Hybrid Search (RRF) ===\n",
    "print(\"\\nüîç Method 3: Hybrid Search (Vector + Keyword Fusion)\")\n",
    "print(\"   ‚Üí Combines exact activity matching + semantic similarity\")\n",
    "print(\"-\" * 100)\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Execute search and collect results (synchronous)\n",
    "hybrid_search_results = search_client.search(\n",
    "    search_text=test_query,  # Enable keyword search\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"title\", \"category\", \"section\"],\n",
    "    top=3\n",
    ")\n",
    "hybrid_results = []\n",
    "for result in hybrid_search_results:\n",
    "    hybrid_results.append(result)\n",
    "\n",
    "# Display results\n",
    "for i, r in enumerate(hybrid_results, 1):\n",
    "    section = r.get('section', 'Other')\n",
    "    print(f\"   {i}. [{section}] {r['title']}\")\n",
    "sys.stdout.flush()\n",
    "time.sleep(0.1)  # Wait for output completion\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"üìä Search Results Analysis:\")\n",
    "print(\"=\" * 100)\n",
    "print(\"‚úÖ Keyword Search (most accurate in this case):\")\n",
    "print(\"   - Ranks destinations that exactly contain 'surfing' keyword at top\")\n",
    "print(\"   - Surf spots like Yangyang surfing, Busan Haeundae are mainly searched\")\n",
    "print(\"\\n‚ö†Ô∏è  Vector Search:\")\n",
    "print(\"   - Also includes conceptual destinations related to 'marine activities' (semantically similar but may not mention surfing)\")\n",
    "print(\"   - Beach and ocean-related destinations may be searched broadly\")\n",
    "print(\"\\n‚≠ê Hybrid Search (recommended):\")\n",
    "print(\"   - Combines keyword search accuracy + vector search semantic understanding\")\n",
    "print(\"   - Prioritizes destinations with explicit surfing mention + appropriately includes related marine activity places\")\n",
    "print(\"\\nüí° Conclusion: Keyword search is strong for specific activity/place name searches,\")\n",
    "print(\"         but hybrid provides more comprehensive results in actual production\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9377451d",
   "metadata": {},
   "source": [
    "### üìà Search Results Analysis Guide\n",
    "\n",
    "The above experimental results demonstrate the characteristics of Azure AI Search's 3 search methods:\n",
    "\n",
    "---\n",
    "\n",
    "#### üîë Keyword Search (BM25)\n",
    "- **Strengths**: Exact keyword matching (surfing, hanok village, Seoraksan, etc.)\n",
    "- **Weaknesses**: Weak synonym/similar concept search (e.g., \"healing\" search won't find \"relaxation\", \"meditation\" documents)\n",
    "- **Recommended Use Cases**: \n",
    "  - Specific place names/activity search (e.g., \"Gyeongbokgung\", \"Jeju Island\", \"surfing\")\n",
    "  - Technical term search (for technical documentation RAG)\n",
    "\n",
    "#### üß† Vector Search (Semantic Search)\n",
    "- **Strengths**: Semantic similarity search (e.g., \"healing destination\" ‚Üí meditation/yoga/nature retreat places)\n",
    "- **Weaknesses**: Accuracy may drop when exact keyword matching is important\n",
    "- **Recommended Use Cases**:\n",
    "  - Abstract concept search (e.g., \"family travel\", \"healing places\")\n",
    "  - Multilingual/synonym search (embedding model understands meaning)\n",
    "\n",
    "#### ‚öñÔ∏è Hybrid Search (RRF)\n",
    "- **Strengths**: Keyword + vector search combination ‚Üí ensures both accuracy and semantic understanding\n",
    "- **Production Recommendation**: Hybrid is optimal for most real services\n",
    "- **How it Works**: \n",
    "  - Re-ranks keyword search Top-K and vector search Top-K using RRF (Reciprocal Rank Fusion)\n",
    "  - Documents ranked high in both methods get higher final scores\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ Practice Tips\n",
    "Try experimenting with various queries:\n",
    "```python\n",
    "# When exact keyword matching is important\n",
    "test_query = \"Jeju Island Seopjikoji\"\n",
    "\n",
    "# When semantic search is advantageous\n",
    "test_query = \"Natural retreat where I can heal with family\"\n",
    "\n",
    "# Activity-focused search\n",
    "test_query = \"Places to enjoy diving and scuba\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1dfe6b",
   "metadata": {},
   "source": [
    "## 11. Update Configuration File\n",
    "\n",
    "Save the index name to `config.json` so it can be used in Notebook 3 (Agent Deployment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e821749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload config.json\n",
    "with open(\"./config.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Add index name\n",
    "config[\"search_index\"] = index_name\n",
    "\n",
    "# Save updated configuration\n",
    "with open(\"./config.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(config, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"‚úÖ Configuration file updated successfully!\")\n",
    "print(f\"   - Index name: {index_name}\")\n",
    "print(f\"   - Saved to: config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a297d0",
   "metadata": {},
   "source": [
    "## üìç Next Steps\n",
    "\n",
    "You have successfully configured the RAG knowledge base! Now proceed to the following notebooks in order:\n",
    "\n",
    "1. **Notebook 03**: Deploy Foundry Agent (`03_deploy_foundry_agent.ipynb`)\n",
    "2. **Notebook 04**: Deploy MAF-based Agent (`04_deploy_foundry_agent_with_maf.ipynb`)\n",
    "3. **Notebook 05**: MAF Workflow Patterns Practice (`05_maf_workflow_patterns.ipynb`)\n",
    "4. **Notebook 06**: MAF Dev UI Practice (`06_maf_dev_ui.ipynb`)\n",
    "5. **Notebook 07**: Evaluate Agents (`07_evaluate_agents.ipynb`)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
