# Azure AI Project Configuration (Microsoft Agent Framework)
# Get these values from Azure AI Foundry portal or config.json after Lab 1

# Azure AI Project Endpoint (Microsoft Agent Framework uses this variable name)
# Format: https://<your-project>.services.ai.azure.com/api/projects/<project-id>
# This is automatically generated in Lab 4 from config.json
AZURE_AI_PROJECT_ENDPOINT=https://your-project-name.services.ai.azure.com/api/projects/your-project-id

# Model Deployment Name
# The name of your deployed model in Azure OpenAI
# Examples: gpt-4o, gpt-4, gpt-35-turbo, gpt-4o-mini
# 
# üîß How to change the model:
# 1. Update this value in your .env file (e.g., AZURE_AI_MODEL_DEPLOYMENT_NAME=gpt-4)
# 2. Ensure the model is deployed in your Azure OpenAI resource
# 3. No code changes required - the application will use this environment variable
# 
# üìù Note: This is the ONLY place you need to change to switch models
AZURE_AI_MODEL_DEPLOYMENT_NAME=gpt-4o

# MCP Server Endpoint (for Tool Agent)
# The endpoint of your Model Context Protocol server for external tools
# Tools: weather API (real-time data from wttr.in)
# This is automatically set in Lab 4 from config.json (mcp_endpoint)
MCP_ENDPOINT=https://your-mcp-server.azurecontainerapps.io

# Azure AI Search Configuration (for Research Agent with RAG)
# Get these from your Azure AI Search service for RAG functionality
# SEARCH_ENDPOINT is automatically set in Lab 4 from config.json
# SEARCH_INDEX is the name of your knowledge base index
# SEARCH_KEY is the admin key for Azure AI Search (automatically retrieved in Lab 4)
# Required for Research Agent to perform knowledge base searches
SEARCH_ENDPOINT=https://your-search-service.search.windows.net/
SEARCH_INDEX=ai-agent-knowledge-base
SEARCH_KEY=your-search-admin-key-here

# Application Insights Configuration (for Application Analytics)
# Get this from your Application Insights resource in Azure Portal
# This is automatically retrieved in Lab 4
# ‚ö†Ô∏è  NOTE: Application Insights is NOT used in Agent Framework
# This variable is set for future implementation but currently not used
# Optional: Remove this section if you don't want to use Application Insights
APPLICATIONINSIGHTS_CONNECTION_STRING=InstrumentationKey=your-key;IngestionEndpoint=https://region.in.applicationinsights.azure.com/

# OpenTelemetry Configuration (for Tracing)
# These settings control how telemetry data is collected and exported
# ‚ö†Ô∏è  NOTE: OpenTelemetry is NOT implemented in Agent Framework
# These variables are set for future implementation but currently not used
# Unlike Foundry Agent (Lab 3), Agent Framework does not auto-collect telemetry
OTEL_SERVICE_NAME=agent-framework-workflow
OTEL_TRACES_EXPORTER=azure_monitor
OTEL_METRICS_EXPORTER=azure_monitor
OTEL_LOGS_EXPORTER=azure_monitor
OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED=true

# GenAI Content Recording (Prompt/Completion in Tracing UI)
# Enable this to see Input/Output in Azure AI Foundry Tracing UI
# ‚ö†Ô∏è  NOTE: Tracing is NOT implemented in Agent Framework
# This variable is set for future implementation but currently not used
# WARNING: This may expose sensitive data - use with caution in production
# Options: true (enable) or false (disable)
AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED=true

# Masking / PII Handling
# Controls how sensitive information is masked in traces
# Options: off (no masking), standard (basic masking), strict (aggressive masking)
AGENT_MASKING_MODE=standard

# Authentication
# This implementation uses Azure CLI credentials (az login)
# Make sure you're logged in: az login
# For Container Apps deployment, Managed Identity is used instead
